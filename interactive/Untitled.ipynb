{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd63a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@file:DependsOn(\"org.jetbrains.kotlinx:kotlin-deeplearning-api:0.3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7edfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.jetbrains.kotlinx.dl.api.core.Sequential\n",
    "import org.jetbrains.kotlinx.dl.api.core.WritingMode\n",
    "import org.jetbrains.kotlinx.dl.api.core.activation.Activations\n",
    "import org.jetbrains.kotlinx.dl.api.core.initializer.HeNormal\n",
    "import org.jetbrains.kotlinx.dl.api.core.initializer.HeUniform\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.convolutional.Conv2D\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.convolutional.ConvPadding\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.core.Dense\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.core.Input\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.pooling.MaxPool2D\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.reshaping.Flatten\n",
    "import org.jetbrains.kotlinx.dl.api.core.loss.Losses\n",
    "import org.jetbrains.kotlinx.dl.api.core.metric.Metrics\n",
    "import org.jetbrains.kotlinx.dl.api.core.optimizer.Adam\n",
    "import org.jetbrains.kotlinx.dl.api.core.summary.logSummary\n",
    "import org.jetbrains.kotlinx.dl.dataset.OnFlyImageDataset\n",
    "import org.jetbrains.kotlinx.dl.dataset.dogsCatsDatasetPath\n",
    "import org.jetbrains.kotlinx.dl.dataset.preprocessor.*\n",
    "import org.jetbrains.kotlinx.dl.dataset.preprocessor.generator.FromFolders\n",
    "import org.jetbrains.kotlinx.dl.dataset.preprocessor.image.InterpolationType\n",
    "import org.jetbrains.kotlinx.dl.dataset.preprocessor.image.resize\n",
    "import java.io.File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6233c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val PATH_TO_MODEL = \"savedmodels/vgg11\"\n",
    "val EPOCHS = 3\n",
    "val TRAINING_BATCH_SIZE = 32\n",
    "val TEST_BATCH_SIZE = 256\n",
    "val NUM_LABELS = 2\n",
    "val NUM_CHANNELS = 3L\n",
    "val IMAGE_SIZE = 64L\n",
    "val TRAIN_TEST_SPLIT_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdde6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "val vgg11 = Sequential.of(\n",
    "    Input(\n",
    "        IMAGE_SIZE,\n",
    "        IMAGE_SIZE,\n",
    "        NUM_CHANNELS\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 32,\n",
    "        kernelSize = longArrayOf(3, 3),\n",
    "        strides = longArrayOf(1, 1, 1, 1),\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeNormal(),\n",
    "        padding = ConvPadding.SAME\n",
    "    ),\n",
    "    MaxPool2D(\n",
    "        poolSize = intArrayOf(1, 2, 2, 1),\n",
    "        strides = intArrayOf(1, 2, 2, 1)\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernelSize = longArrayOf(3, 3),\n",
    "        strides = longArrayOf(1, 1, 1, 1),\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeNormal(),\n",
    "        padding = ConvPadding.SAME\n",
    "    ),\n",
    "    MaxPool2D(\n",
    "        poolSize = intArrayOf(1, 2, 2, 1),\n",
    "        strides = intArrayOf(1, 2, 2, 1)\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 128,\n",
    "        kernelSize = longArrayOf(3, 3),\n",
    "        strides = longArrayOf(1, 1, 1, 1),\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeNormal(),\n",
    "        padding = ConvPadding.SAME\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 128,\n",
    "        kernelSize = longArrayOf(3, 3),\n",
    "        strides = longArrayOf(1, 1, 1, 1),\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeNormal(),\n",
    "        padding = ConvPadding.SAME\n",
    "    ),\n",
    "    MaxPool2D(\n",
    "        poolSize = intArrayOf(1, 2, 2, 1),\n",
    "        strides = intArrayOf(1, 2, 2, 1)\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 256,\n",
    "        kernelSize = longArrayOf(3, 3),\n",
    "        strides = longArrayOf(1, 1, 1, 1),\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeNormal(),\n",
    "        padding = ConvPadding.SAME\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 256,\n",
    "        kernelSize = longArrayOf(3, 3),\n",
    "        strides = longArrayOf(1, 1, 1, 1),\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeNormal(),\n",
    "        padding = ConvPadding.SAME\n",
    "    ),\n",
    "    MaxPool2D(\n",
    "        poolSize = intArrayOf(1, 2, 2, 1),\n",
    "        strides = intArrayOf(1, 2, 2, 1)\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 256,\n",
    "        kernelSize = longArrayOf(3, 3),\n",
    "        strides = longArrayOf(1, 1, 1, 1),\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeNormal(),\n",
    "        padding = ConvPadding.SAME\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 256,\n",
    "        kernelSize = longArrayOf(3, 3),\n",
    "        strides = longArrayOf(1, 1, 1, 1),\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeNormal(),\n",
    "        padding = ConvPadding.SAME\n",
    "    ),\n",
    "    MaxPool2D(\n",
    "        poolSize = intArrayOf(1, 2, 2, 1),\n",
    "        strides = intArrayOf(1, 2, 2, 1)\n",
    "    ),\n",
    "    Flatten(),\n",
    "    Dense(\n",
    "        outputSize = 1024,\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeUniform()\n",
    "    ),\n",
    "    Dense(\n",
    "        outputSize = 512,\n",
    "        activation = Activations.Relu,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeUniform()\n",
    "    ),\n",
    "    Dense(\n",
    "        outputSize = NUM_LABELS,\n",
    "        activation = Activations.Linear,\n",
    "        kernelInitializer = HeNormal(),\n",
    "        biasInitializer = HeUniform()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698277cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "println(\"Loading dataset...\")\n",
    "val dogsCatsImages = dogsCatsDatasetPath()\n",
    "println(\"Loaded dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20a260ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n",
      "Done pre-processing\n"
     ]
    }
   ],
   "source": [
    "println(\"Creating pipeline with pre-processing...\")\n",
    "val preprocessing: Preprocessing = preprocess {\n",
    "    load {\n",
    "        pathToData = File(dogsCatsImages)\n",
    "        imageShape = ImageShape(channels = 3)\n",
    "        labelGenerator = FromFolders(mapping = mapOf(\"cat\" to 0, \"dog\" to 1))\n",
    "    }\n",
    "    transformImage {\n",
    "        resize {\n",
    "            outputHeight = IMAGE_SIZE.toInt()\n",
    "            outputWidth = IMAGE_SIZE.toInt()\n",
    "            interpolation = InterpolationType.NEAREST\n",
    "        }\n",
    "//            convert { colorMode = ColorMode.BGR }\n",
    "    }\n",
    "    transformTensor {\n",
    "        rescale {\n",
    "            scalingCoefficient = 255f\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "val dataset = OnFlyImageDataset.create(preprocessing).shuffle()\n",
    "val (train, test) = dataset.split(TRAIN_TEST_SPLIT_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f870c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kotlin.contracts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7297348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training...\n",
      "Training time: 374.765\n",
      "Accuracy: 0.7722426652908325\n"
     ]
    }
   ],
   "source": [
    "println(\"Started training...\")\n",
    "vgg11.compile(Adam(), Losses.SOFT_MAX_CROSS_ENTROPY_WITH_LOGITS, Metrics.ACCURACY)\n",
    "vgg11.logSummary()\n",
    "\n",
    "val start = System.currentTimeMillis()\n",
    "vgg11.fit(dataset = train, epochs = EPOCHS, batchSize = TRAINING_BATCH_SIZE)\n",
    "println(\"Training time: ${(System.currentTimeMillis() - start) / 1000f}\")\n",
    "\n",
    "vgg11.save(File(PATH_TO_MODEL), writingMode = WritingMode.OVERRIDE)\n",
    "\n",
    "val accuracy = vgg11.evaluate(dataset = test, batchSize = TEST_BATCH_SIZE).metrics[Metrics.ACCURACY]\n",
    "\n",
    "println(\"Accuracy: $accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.6.20-dev-6372"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
